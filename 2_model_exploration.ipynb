{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique groups in the dataset\n",
    "df_oasis = pd.read_csv('oasis_long_processed.csv')\n",
    "print(\"Unique groups in 'Group' column:\", df_oasis['Group'].unique())\n",
    "print(\"Number of unique groups:\", df_oasis['Group'].nunique())\n",
    "print(df_oasis['Group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Results Storage Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ML MODEL RESULTS STORAGE FRAMEWORK\n",
    "# =============================================================================\n",
    "\n",
    "# Creating holders to store the model performance results\n",
    "ML_Model = []\n",
    "ML_Config = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "precision = []\n",
    "auc_roc = []  # Adding a holder for AUC-ROC\n",
    "\n",
    "# Function to call for storing the results\n",
    "def storeResults(model, config, a, b, c, d, e):\n",
    "    \"\"\"\n",
    "    Store model performance results\n",
    "    \n",
    "    Parameters:\n",
    "    model: Name of the ML model\n",
    "    config: Configuration name (preprocessing steps applied)\n",
    "    a: Accuracy score\n",
    "    b: F1 score\n",
    "    c: Recall score\n",
    "    d: Precision score\n",
    "    e: AUC-ROC score\n",
    "    \"\"\"\n",
    "    ML_Model.append(model)\n",
    "    ML_Config.append(config)\n",
    "    accuracy.append(round(a, 6))\n",
    "    f1_score.append(round(b, 6))\n",
    "    recall.append(round(c, 6))\n",
    "    precision.append(round(d, 6))\n",
    "    auc_roc.append(round(e, 6))\n",
    "\n",
    "# Function to display and save results\n",
    "def displayAndSaveResults(filename_prefix='model_results'):\n",
    "    \"\"\"\n",
    "    Create dataframe from results, display, and save to CSV\n",
    "    \n",
    "    Parameters:\n",
    "    filename_prefix: Prefix for the CSV filenames\n",
    "    \"\"\"\n",
    "    # Creating the dataframe\n",
    "    result = pd.DataFrame({\n",
    "        'ML Model': ML_Model,\n",
    "        'Configuration': ML_Config,\n",
    "        'Accuracy': [f\"{acc * 100:.3f}%\" for acc in accuracy],\n",
    "        'F1 Score': [f\"{f1 * 100:.3f}%\" for f1 in f1_score],\n",
    "        'Recall': [f\"{rec * 100:.3f}%\" for rec in recall],\n",
    "        'Precision': [f\"{prec * 100:.3f}%\" for prec in precision],\n",
    "        'ROC_AUC': [f\"{roc * 100:.3f}%\" for roc in auc_roc],\n",
    "    })\n",
    "    \n",
    "    # Remove duplicates if any\n",
    "    result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL PERFORMANCE RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    print(result.to_string(index=False))\n",
    "    \n",
    "    # Saving the result to a CSV file\n",
    "    result.to_csv(f'{filename_prefix}.csv', index=False)\n",
    "    print(f\"\\nResults saved to {filename_prefix}.csv\")\n",
    "    \n",
    "    # Sorting the dataframe on accuracy and F1 Score\n",
    "    sorted_result = result.sort_values(by=['Accuracy', 'F1 Score'], ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\")\n",
    "    print(\"=\"*100)\n",
    "    print(sorted_result.to_string(index=False))\n",
    "    \n",
    "    # Saving the sorted result to a CSV file\n",
    "    sorted_result.to_csv(f'sorted_{filename_prefix}.csv', index=False)\n",
    "    print(f\"\\nSorted results saved to sorted_{filename_prefix}.csv\")\n",
    "    \n",
    "    return result, sorted_result\n",
    "\n",
    "# Function to clear results (useful when running multiple experiments)\n",
    "def clearResults():\n",
    "    \"\"\"Clear all stored results\"\"\"\n",
    "    global ML_Model, ML_Config, accuracy, f1_score, recall, precision, auc_roc\n",
    "    ML_Model.clear()\n",
    "    ML_Config.clear()\n",
    "    accuracy.clear()\n",
    "    f1_score.clear()\n",
    "    recall.clear()\n",
    "    precision.clear()\n",
    "    auc_roc.clear()\n",
    "    print(\"Results cleared!\")\n",
    "\n",
    "# Function to plot model comparison\n",
    "def plotModelComparison(result_df):\n",
    "    \"\"\"\n",
    "    Create visualization comparing model performances\n",
    "    \n",
    "    Parameters:\n",
    "    result_df: DataFrame with model results\n",
    "    \"\"\"\n",
    "    # Convert percentage strings back to floats for plotting\n",
    "    metrics_cols = ['Accuracy', 'F1 Score', 'Recall', 'Precision', 'ROC_AUC']\n",
    "    plot_df = result_df.copy()\n",
    "    \n",
    "    for col in metrics_cols:\n",
    "        plot_df[col] = plot_df[col].str.rstrip('%').astype(float)\n",
    "    \n",
    "    # Create subplot for each metric\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_cols):\n",
    "        # Group by model and get mean performance across configurations\n",
    "        model_performance = plot_df.groupby('ML Model')[metric].mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Create bar plot\n",
    "        ax = axes[idx]\n",
    "        bars = ax.bar(range(len(model_performance)), model_performance.values, \n",
    "                      color=plt.cm.Blues(np.linspace(0.4, 0.9, len(model_performance))))\n",
    "        ax.set_xticks(range(len(model_performance)))\n",
    "        ax.set_xticklabels(model_performance.index, rotation=45, ha='right')\n",
    "        ax.set_ylabel(f'{metric} (%)')\n",
    "        ax.set_title(f'Average {metric} by Model', fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Hide the last subplot if we have 5 metrics\n",
    "    if len(metrics_cols) == 5:\n",
    "        axes[5].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Model results storage framework loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading for OASIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('oasis_long_processed.csv')\n",
    "\n",
    "# ====================================================================\n",
    "#                      START: DATA PREPROCESSING\n",
    "# ====================================================================\n",
    "\n",
    "# 1. Encode the target variable 'Group' into numerical labels.\n",
    "# The LabelEncoder will assign a unique integer to each class, for example:\n",
    "# 'Nondemented' -> 2, 'Demented' -> 1, 'Converted' -> 0\n",
    "le = LabelEncoder()\n",
    "df['Group'] = le.fit_transform(df['Group'])\n",
    "\n",
    "# 2. Separate features (X) and target (y).\n",
    "# We now use the numerically encoded 'Group' column as our target.\n",
    "X = df.drop('Group', axis=1)\n",
    "y = df['Group']\n",
    "\n",
    "# 3. Drop identifier columns from the features.\n",
    "# These columns are unique for each scan and don't help the model generalize.\n",
    "X = X.drop(['Subject ID', 'MRI ID'], axis=1)\n",
    "\n",
    "# 4. Convert all remaining categorical columns to a numeric format.\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# ====================================================================\n",
    "#                       END: DATA PREPROCESSING\n",
    "# ====================================================================\n",
    "\n",
    "# Split the fully preprocessed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"\\nPreprocessed data loaded successfully!\")\n",
    "print(\"The data has been cleaned and all features are now numeric.\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\\n\")\n",
    "\n",
    "print(\"A sample of the processed X_train data:\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with PCA 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "\n",
    "# Step 1: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 2.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 2.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 2.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.90)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 3: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Support Vector Machine 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {svc.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with PCA 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "\n",
    "# Step 1: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 2.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 2.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 2.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 3: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Support Vector Machine 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {svc.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with PCA 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "\n",
    "# Step 1: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 2.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 2.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 2.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 3: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Support Vector Machine 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {svc.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with PCA 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.90)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Random Forest 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with PCA 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Random Forest 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with PCA 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Random Forest 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting with PCA 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.90)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Gradient Boosting 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {gbc.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting with PCA 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Gradient Boosting 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {gbc.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting with PCA 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Gradient Boosting 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {gbc.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost with PCA 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.90)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 2, 3]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'AdaBoost 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {ab.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost with PCA 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 2, 3]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'AdaBoost 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {ab.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost with PCA 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 2, 3]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'AdaBoost 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {ab.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with PCA 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.90)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb_model = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    xgb_model.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_xgb = xgb_model.predict(X_test_cfg)\n",
    "    y_test_xgb_proba = xgb_model.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'XGBoost 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {xgb_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with PCA 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb_model = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    xgb_model.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_xgb = xgb_model.predict(X_test_cfg)\n",
    "    y_test_xgb_proba = xgb_model.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'XGBoost 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {xgb_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with PCA 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb_model = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    xgb_model.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_xgb = xgb_model.predict(X_test_cfg)\n",
    "    y_test_xgb_proba = xgb_model.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'XGBoost 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {xgb_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with PCA 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging (using Decision Tree) ===\")\n",
    "tree_estimator = DecisionTreeClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=tree_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.90)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Bagging Classifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.8, 1.0],\n",
    "    'max_features': [0.8, 1.0],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [3, 5, None]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(BaggingClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Bagging 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {bag.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with PCA 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging (using Decision Tree) ===\")\n",
    "tree_estimator = DecisionTreeClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=tree_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Bagging Classifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.8, 1.0],\n",
    "    'max_features': [0.8, 1.0],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [3, 5, None]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(BaggingClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Bagging 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {bag.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with PCA 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging (using Decision Tree) ===\")\n",
    "tree_estimator = DecisionTreeClassifier(random_state=42)\n",
    "rfecv = RFECV(estimator=tree_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_normalized, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "X_train_rfe = rfecv.transform(X_train_normalized)\n",
    "X_test_rfe = rfecv.transform(X_test_normalized)\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Bagging Classifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.8, 1.0],\n",
    "    'max_features': [0.8, 1.0],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [3, 5, None]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(BaggingClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    storeResults(\n",
    "        'Bagging 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    )\n",
    "    print(f\"Results for {name} configuration stored.\")\n",
    "    print(f\"Best hyperparameters: {bag.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Model with PCA 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, sorted_result = displayAndSaveResults(filename_prefix='oasis_model_results')\n",
    "\n",
    "# Plot the model comparison\n",
    "if not result.empty:\n",
    "    plotModelComparison(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataframe\n",
    "result = pd.DataFrame({\n",
    "    'ML Model': ML_Model,\n",
    "    'Configuration': ML_Config,\n",
    "    'Accuracy': [f\"{acc * 100:.3f}%\" for acc in accuracy],\n",
    "    'F1 Score': [f\"{f1 * 100:.3f}%\" for f1 in f1_score],\n",
    "    'Recall': [f\"{rec * 100:.3f}%\" for rec in recall],\n",
    "    'Precision': [f\"{prec * 100:.3f}%\" for prec in precision],\n",
    "    'ROC_AUC': [f\"{roc * 100:.3f}%\" for roc in auc_roc],\n",
    "})\n",
    "\n",
    "# Remove duplicates based on model and configuration\n",
    "result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL PERFORMANCE RESULTS\")\n",
    "print(\"=\" * 100)\n",
    "print(result.to_string(index=False))\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result.to_csv('results/model_results.csv', index=False)\n",
    "print(\"\\nResults saved to model_results.csv\")\n",
    "\n",
    "# Sort by Accuracy and F1 Score\n",
    "sorted_result = result.sort_values(by=['F1 Score', 'Accuracy'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\")\n",
    "print(\"=\" * 100)\n",
    "print(sorted_result.to_string(index=False))\n",
    "\n",
    "# Save the sorted result\n",
    "sorted_result.to_csv('results/sorted_model_results.csv', index=False)\n",
    "print(\"\\nSorted results saved to sorted_model_results.csv\")\n",
    "\n",
    "# Extract top configuration per ML model\n",
    "top_per_model = sorted_result.groupby('ML Model', as_index=False).first()\n",
    "\n",
    "# Display and save the top configuration table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP CONFIGURATION PER MODEL\")\n",
    "print(\"=\" * 100)\n",
    "print(top_per_model.to_string(index=False))\n",
    "\n",
    "top_per_model.to_csv('results/top_configurations.csv', index=False)\n",
    "print(\"\\nTop configuration per model saved to top_configurations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read input CSV\n",
    "df = pd.read_csv('results/top_configurations.csv')\n",
    "\n",
    "# Sort by 'Accuracy' column in descending order\n",
    "df_sorted = df.sort_values(by=['F1 Score', 'Accuracy'], ascending=False)\n",
    "\n",
    "# Save the sorted DataFrame to a new CSV\n",
    "df_sorted.to_csv('results/sorted_top_configurations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
